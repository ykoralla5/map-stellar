{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import threading\n",
    "import subprocess\n",
    "import pandas\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "from resource import *\n",
    "import resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, -1)\n"
     ]
    }
   ],
   "source": [
    "print(getrlimit(resource.RLIMIT_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource.setrlimit(resource.RLIMIT_AS, (4294967296,4294967296)) # 4GB RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_MAIN_CONFIG = {\n",
    "    'dbname': 'captivecoredb_history',\n",
    "    'user': 'captivecore',\n",
    "    'password': 'stellar123',\n",
    "    'host': 'localhost',\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "DB_FILTERED_CONFIG = {\n",
    "    'dbname': 'captivecoredb_fil',\n",
    "    'user': 'jdbc',\n",
    "    'password': 'stellar123',\n",
    "    'host': 'localhost',\n",
    "    'port': 5432\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_main = psycopg2.connect(database=\"captivecoredb\", user=\"matija\", password=\"stellar123\")\n",
    "cur_main = conn_main.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_his = psycopg2.connect(database=\"captivecoredb_history\", user=\"matija\", password=\"stellar123\")\n",
    "cur_his = conn_his.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_fil = psycopg2.connect(database=\"captivecoredb_fil\", user=\"matija\", password=\"stellar123\")\n",
    "cur_fil = conn_fil.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1\n",
      "0     277  55403411\n",
      "1     685  55403412\n",
      "2     290  55403413\n",
      "3     262  55403414\n",
      "4     295  55403415\n",
      "...   ...       ...\n",
      "2614  192  55406025\n",
      "2615  224  55406026\n",
      "2616  191  55406027\n",
      "2617  203  55406028\n",
      "2618  170  55406029\n",
      "\n",
      "[2619 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Main DB\n",
    "try:\n",
    "    cur_main.execute(\"SELECT count(*), ledger_sequence FROM history_transactions where ledger_sequence between 55403411 and 55406029 group by ledger_sequence order by ledger_sequence asc;\")\n",
    "    #captivecore_transactions = cur_his.fetchone()[0]\n",
    "    captivecore_transactions_count = DataFrame(cur_main.fetchall())\n",
    "    print(captivecore_transactions_count)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn_main.rollback()  # Rollback on failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0         1\n",
      "0    150  54118601\n",
      "1    161  54118602\n",
      "2    196  54118603\n",
      "3    142  54118604\n",
      "4    304  54118605\n",
      "..   ...       ...\n",
      "995  231  54119596\n",
      "996  209  54119597\n",
      "997  236  54119598\n",
      "998  291  54119599\n",
      "999  309  54119600\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "(-1, -1)\n"
     ]
    }
   ],
   "source": [
    "# History DB\n",
    "try:\n",
    "    cur_his.execute(\"SELECT count(*), ledger_sequence FROM history_transactions where ledger_sequence between 55403411 and 55406029 group by ledger_sequence order by ledger_sequence asc;\")\n",
    "    #captivecore_transactions = cur_his.fetchone()[0]\n",
    "    captivecore_transactions_count = DataFrame(cur_his.fetchall())\n",
    "    print(captivecore_transactions_count)\n",
    "    print(getrlimit(resource.RLIMIT_DATA))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn_his.rollback()  # Rollback on failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1\n",
      "0     186  55404030\n",
      "1     312  55404031\n",
      "2     172  55404032\n",
      "3     243  55404033\n",
      "4     199  55404034\n",
      "...   ...       ...\n",
      "1895  192  55406025\n",
      "1896  224  55406026\n",
      "1897  191  55406027\n",
      "1898  203  55406028\n",
      "1899  170  55406029\n",
      "\n",
      "[1900 rows x 2 columns]\n",
      "(-1, -1)\n",
      "(-1, -1)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cur_fil.execute(\"SELECT count(*), ledger_sequence FROM transactions where ledger_sequence between 55403411 and 55406029 group by ledger_sequence order by ledger_sequence asc;\")\n",
    "    captivecore_fil_transactions_count = DataFrame(cur_fil.fetchall())\n",
    "    print(captivecore_fil_transactions_count)\n",
    "    print(getrlimit(resource.RLIMIT_DATA))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn_fil.rollback()  # Rollback on failure\n",
    "print(getrlimit(resource.RLIMIT_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ledgers = captivecore_transactions_count[1]\n",
    "ledgers_not_in_filtered_2 = ledgers.to_frame()\n",
    "#ledgers_not_in_filtered['sequence'] = captivecore_fil_transactions_count[1]\n",
    "ledgers_not_in_filtered_2['present_in_fil'] = captivecore_transactions_count[1].isin(captivecore_fil_transactions_count[1])\n",
    "#ledgers_not_in_filtered_2['present_in_main'] = captivecore_fil_transactions_count[1].isin(captivecore_transactions_count[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "captivecore_transactions_count['not_ingested_transactions'] = captivecore_transactions_count[0] - captivecore_fil_transactions_count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_his.execute(\"TRUNCATE history_ledgers;\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0         1\n",
      "0    234674990124244992  54639529\n",
      "1    234674990124605440  54639529\n",
      "2    234674990123868160  54639529\n",
      "3    234674990123872256  54639529\n",
      "4    234674990123929600  54639529\n",
      "..                  ...       ...\n",
      "467  235466720101093376  54823868\n",
      "468  235466720101097472  54823868\n",
      "469  235466720101101568  54823868\n",
      "470  235466720101105664  54823868\n",
      "471  235466720101109760  54823868\n",
      "\n",
      "[472 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cur1.execute(\"SELECT id, ledger_sequence FROM history_transactions where ledger_sequence = 54823868 or ledger_sequence = 54639529;\")\n",
    "    #captivecore_transactions = cur1.fetchone()[0]\n",
    "    captivecore_transactions_54479614_54394229 = DataFrame(cur1.fetchall())\n",
    "    print(captivecore_transactions_54479614_54394229)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn1.rollback()  # Rollback on failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0         1\n",
      "0    234674990123847680  54639529\n",
      "1    234674990123851776  54639529\n",
      "2    234674990123855872  54639529\n",
      "3    234674990123859968  54639529\n",
      "4    234674990123864064  54639529\n",
      "..                  ...       ...\n",
      "464  235466720101093376  54823868\n",
      "465  235466720101097472  54823868\n",
      "466  235466720101101568  54823868\n",
      "467  235466720101105664  54823868\n",
      "468  235466720101109760  54823868\n",
      "\n",
      "[469 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cur2.execute(\"SELECT id, ledger_sequence FROM transactions where ledger_sequence = 54823868 or ledger_sequence = 54639529;\")\n",
    "    #captivecore_transactions = cur1.fetchone()[0]\n",
    "    captivecore_fil_transactions_54479614_54394229 = DataFrame(cur2.fetchall())\n",
    "    print(captivecore_fil_transactions_54479614_54394229)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn2.rollback()  # Rollback on failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "captivecore_transactions_54479614_54394229['present_in_fil'] = captivecore_transactions_54479614_54394229[0].isin(captivecore_fil_transactions_54479614_54394229[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888566\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cur1.execute(\"SELECT count(*) FROM history_ledgers where sequence between 54284800 and 55173365;\")\n",
    "    captivecore_ledgers = cur1.fetchone()[0]\n",
    "    #captivecore_transactions_count = DataFrame(cur1.fetchall())\n",
    "    print(captivecore_ledgers)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn1.rollback()  # Rollback on failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888566\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cur2.execute(\"SELECT count(*) FROM ledgers where sequence between 54284800 and 55173365;\")\n",
    "    captivecore_fil_ledgers = cur2.fetchone()[0]\n",
    "    #captivecore_transactions_count = DataFrame(cur1.fetchall())\n",
    "    print(captivecore_fil_ledgers)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn2.rollback()  # Rollback on failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file was last modified at: Tue Jan 28 19:40:26 2025\n",
      "Offset 779523771 not found in log file.\n",
      "Offset 779523771 not found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import time\n",
    "\n",
    "def find_offset_in_log(file_path, target_offset):\n",
    "    with open(file_path, 'rb') as log_file:\n",
    "\n",
    "        # The log files are organized in batches of messages\n",
    "        while True:\n",
    "            # Read the next batch of messages (4 bytes to indicate the length of the log entry)\n",
    "            length_bytes = log_file.read(4)\n",
    "            if len(length_bytes) < 4:\n",
    "                break  # End of file reached or incomplete entry\n",
    "\n",
    "            # Decode the length of the log entry (int)\n",
    "            length = struct.unpack('>I', length_bytes)[0]\n",
    "\n",
    "            # Read the log entry data\n",
    "            log_data = log_file.read(length)\n",
    "            if len(log_data) < length:\n",
    "                break  # Incomplete log data, break out\n",
    "\n",
    "            # Check if we have enough data to unpack the offset (8 bytes)\n",
    "            for i in range(len(log_data) - 7):  # Ensure we have 8 bytes to check\n",
    "                possible_offset = struct.unpack('>Q', log_data[i:i+8])[0]\n",
    "\n",
    "                # Check if we found the target offset\n",
    "                if possible_offset == target_offset:\n",
    "                    print(f\"Found message with offset {target_offset} starting at byte {i} in log data.\")\n",
    "                    print(f\"Log data: {log_data[i:i+8]}\")\n",
    "                    return True  # Found the message\n",
    "\n",
    "        print(f\"Offset {target_offset} not found in log file.\")\n",
    "        return False  # Offset not found\n",
    "\n",
    "def get_file_creation_time(file_path):\n",
    "    # Get the last modified time of the file\n",
    "    modified_time = os.path.getmtime(file_path)\n",
    "    # Convert it to a human-readable format\n",
    "    return time.ctime(modified_time)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    log_file_path = '/home/matija/kafka_2.13-3.8.0/logs/server/captivecore.public.history_transactions-0/00000000000004773221.log'  # Replace with your log file path\n",
    "    print(f\"Log file was last modified at: {get_file_creation_time(log_file_path)}\")\n",
    "\n",
    "    target_offset = 779523771  # Replace with your target offset\n",
    "\n",
    "    if find_offset_in_log(log_file_path, target_offset):\n",
    "        print(f\"Offset {target_offset} found.\")\n",
    "    else:\n",
    "        print(f\"Offset {target_offset} not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file was last modified at: Tue Jan 28 19:37:55 2025\n"
     ]
    }
   ],
   "source": [
    "log_file_path = '/home/matija/kafka_2.13-3.8.0/logs/server/captivecore.public.history_transactions-0/00000000000002386165.log'  # Replace with your log file path\n",
    "print(f\"Log file was last modified at: {get_file_creation_time(log_file_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file was last modified at: Mon Jan 27 15:52:23 2025\n"
     ]
    }
   ],
   "source": [
    "log_file_path = '/home/matija/kafka_2.13-3.8.0/logs/server/captivecore.public.history_transactions-0/00000000000652738148.log'  # Replace with your log file path\n",
    "print(f\"Log file was last modified at: {get_file_creation_time(log_file_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file was last modified at: Tue Jan 28 15:00:12 2025\n"
     ]
    }
   ],
   "source": [
    "log_file_path = '/home/matija/kafka_2.13-3.8.0/logs/server/captivecore.public.history_transactions-0/00000000000905953845.log'  # Replace with your log file path\n",
    "print(f\"Log file was last modified at: {get_file_creation_time(log_file_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 14:16:07.642794\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching in /home/matija/kafka_2.13-3.8.0/logs/server/captivecore.public.history_transactions-0/00000000000862923084.log...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "LZ4F_getFrameInfo failed with code: ERROR_frameType_unknown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m log_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/matija/kafka_2.13-3.8.0/logs/server/captivecore.public.history_transactions-0/\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with your log directory path\u001b[39;00m\n\u001b[1;32m     55\u001b[0m target_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m779523771\u001b[39m  \u001b[38;5;66;03m# Replace with your target offset\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[43msearch_in_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_offset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 46\u001b[0m, in \u001b[0;36msearch_in_logs\u001b[0;34m(directory, target_offset)\u001b[0m\n\u001b[1;32m     44\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, filename)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearching in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfind_offset_in_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_offset\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOffset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_offset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Stop searching once we find the offset\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m, in \u001b[0;36mfind_offset_in_log\u001b[0;34m(file_path, target_offset)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_offset_in_log\u001b[39m(file_path, target_offset):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m log_file:\n\u001b[0;32m----> 7\u001b[0m         decompressed_data \u001b[38;5;241m=\u001b[39m \u001b[43mlz4\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(decompressed_data[:\u001b[38;5;241m100\u001b[39m])\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m# Decompress the LZ4-compressed data\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: LZ4F_getFrameInfo failed with code: ERROR_frameType_unknown"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import lz4.frame\n",
    "\n",
    "def find_offset_in_log(file_path, target_offset):\n",
    "    with open(file_path, 'rb') as log_file:\n",
    "        decompressed_data = lz4.frame.decompress(log_file.read())\n",
    "        print(decompressed_data[:100])\n",
    "        # Decompress the LZ4-compressed data\n",
    "        with lz4.frame.open(log_file, mode='rb') as decompressed_file:\n",
    "            while True:\n",
    "                # Read the next 4 bytes to get the length of the log entry\n",
    "                length_bytes = decompressed_file.read(4)\n",
    "                if len(length_bytes) < 4:\n",
    "                    break  # End of file reached or incomplete entry\n",
    "\n",
    "                # Decode the length of the log entry (int)\n",
    "                length = struct.unpack('>I', length_bytes)[0]\n",
    "\n",
    "                # Read the log entry data based on the decoded length\n",
    "                log_data = decompressed_file.read(length)\n",
    "                if len(log_data) < length:\n",
    "                    break  # Incomplete log data, break out\n",
    "\n",
    "                # Check if we have enough data to unpack the offset (8 bytes)\n",
    "                if len(log_data) >= 8:\n",
    "                    # The first 8 bytes of the log entry represent the offset\n",
    "                    message_offset = struct.unpack('>Q', log_data[:8])[0]\n",
    "\n",
    "                    # Debugging: print the current offset and the target offset\n",
    "                    print(f\"Current offset: {message_offset}, Target offset: {target_offset}\")\n",
    "\n",
    "                    # Check if the message offset matches the target offset\n",
    "                    if message_offset == target_offset:\n",
    "                        print(f\"Found message with offset {target_offset} in {file_path}: {log_data}\")\n",
    "                        return True  # Found the message\n",
    "\n",
    "        return False  # Offset not found in this log file\n",
    "\n",
    "def search_in_logs(directory, target_offset):\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.log'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            print(f\"Searching in {file_path}...\")\n",
    "            if find_offset_in_log(file_path, target_offset):\n",
    "                print(f\"Offset {target_offset} found in {file_path}.\")\n",
    "                return True  # Stop searching once we find the offset\n",
    "    print(f\"Offset {target_offset} not found in any log files.\")\n",
    "    return False  # If not found in any files\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    log_directory = '/home/matija/kafka_2.13-3.8.0/logs/server/captivecore.public.history_transactions-0/'  # Replace with your log directory path\n",
    "    target_offset = 779523771  # Replace with your target offset\n",
    "\n",
    "    search_in_logs(log_directory, target_offset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
